{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "390fe2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Processing classes 0 to 9\n",
      "Model type: cnn_lstm\n",
      "Loading classes 0 to 9: ['BaseballPitch', 'Basketball', 'BenchPress', 'Biking', 'Billiards', 'BreastStroke', 'CleanAndJerk', 'Diving', 'Drumming', 'Fencing']\n",
      "Training samples: 1104, Validation samples: 276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /home/alex/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:05<00:00, 8.05MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:10<00:00,  1.95it/s, loss=0.226, acc=37.9]\n",
      "Validation: 100%|██████████| 35/35 [00:10<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.8049, Train Acc: 37.86%\n",
      "Val Loss: 2.0188, Val Acc: 32.25%\n",
      "Saved best model with accuracy: 32.25%\n",
      "\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [02:02<00:00,  1.13it/s, loss=0.183, acc=44.2]\n",
      "Validation: 100%|██████████| 35/35 [00:10<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4676, Train Acc: 44.20%\n",
      "Val Loss: 1.7468, Val Acc: 40.22%\n",
      "Saved best model with accuracy: 40.22%\n",
      "\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:02<00:00,  2.21it/s, loss=0.19, acc=43.8] \n",
      "Validation: 100%|██████████| 35/35 [00:05<00:00,  6.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5167, Train Acc: 43.84%\n",
      "Val Loss: 1.2825, Val Acc: 51.81%\n",
      "Saved best model with accuracy: 51.81%\n",
      "\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:06<00:00,  2.08it/s, loss=0.173, acc=46]  \n",
      "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3831, Train Acc: 46.01%\n",
      "Val Loss: 1.1235, Val Acc: 55.07%\n",
      "Saved best model with accuracy: 55.07%\n",
      "\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:12<00:00,  1.90it/s, loss=0.169, acc=47]  \n",
      "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3546, Train Acc: 47.01%\n",
      "Val Loss: 1.2191, Val Acc: 53.62%\n",
      "\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:18<00:00,  1.76it/s, loss=0.169, acc=48.1]\n",
      "Validation: 100%|██████████| 35/35 [00:07<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3545, Train Acc: 48.10%\n",
      "Val Loss: 1.4030, Val Acc: 52.54%\n",
      "\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:21<00:00,  1.70it/s, loss=0.15, acc=53.3] \n",
      "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1981, Train Acc: 53.26%\n",
      "Val Loss: 1.3053, Val Acc: 56.16%\n",
      "Saved best model with accuracy: 56.16%\n",
      "\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:24<00:00,  1.63it/s, loss=0.139, acc=58]  \n",
      "Validation: 100%|██████████| 35/35 [00:12<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1153, Train Acc: 57.97%\n",
      "Val Loss: 0.9357, Val Acc: 61.23%\n",
      "Saved best model with accuracy: 61.23%\n",
      "\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:26<00:00,  1.59it/s, loss=0.132, acc=57.9]\n",
      "Validation: 100%|██████████| 35/35 [00:07<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0554, Train Acc: 57.88%\n",
      "Val Loss: 1.0652, Val Acc: 57.25%\n",
      "\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:31<00:00,  1.51it/s, loss=0.121, acc=61.1]\n",
      "Validation: 100%|██████████| 35/35 [00:11<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9659, Train Acc: 61.14%\n",
      "Val Loss: 0.8770, Val Acc: 67.39%\n",
      "Saved best model with accuracy: 67.39%\n",
      "\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:43<00:00,  1.33it/s, loss=0.129, acc=59.9]\n",
      "Validation: 100%|██████████| 35/35 [00:09<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0323, Train Acc: 59.87%\n",
      "Val Loss: 1.0593, Val Acc: 59.78%\n",
      "\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:44<00:00,  1.32it/s, loss=0.115, acc=64.3]\n",
      "Validation: 100%|██████████| 35/35 [00:12<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9180, Train Acc: 64.31%\n",
      "Val Loss: 1.1302, Val Acc: 57.61%\n",
      "\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:27<00:00,  1.59it/s, loss=0.123, acc=61.6]\n",
      "Validation: 100%|██████████| 35/35 [00:08<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9862, Train Acc: 61.59%\n",
      "Val Loss: 1.0439, Val Acc: 65.58%\n",
      "\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:30<00:00,  1.53it/s, loss=0.113, acc=64.9]\n",
      "Validation: 100%|██████████| 35/35 [00:09<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9056, Train Acc: 64.86%\n",
      "Val Loss: 0.6604, Val Acc: 77.17%\n",
      "Saved best model with accuracy: 77.17%\n",
      "\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:27<00:00,  1.57it/s, loss=0.104, acc=68.2]\n",
      "Validation: 100%|██████████| 35/35 [00:07<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8311, Train Acc: 68.21%\n",
      "Val Loss: 0.8113, Val Acc: 74.28%\n",
      "\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:31<00:00,  1.51it/s, loss=0.0888, acc=73.1]\n",
      "Validation: 100%|██████████| 35/35 [00:07<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7102, Train Acc: 73.10%\n",
      "Val Loss: 0.5932, Val Acc: 80.43%\n",
      "Saved best model with accuracy: 80.43%\n",
      "\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:29<00:00,  1.54it/s, loss=0.0897, acc=72.9]\n",
      "Validation: 100%|██████████| 35/35 [00:09<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7179, Train Acc: 72.92%\n",
      "Val Loss: 0.5231, Val Acc: 82.25%\n",
      "Saved best model with accuracy: 82.25%\n",
      "\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:26<00:00,  1.60it/s, loss=0.0738, acc=78.8]\n",
      "Validation: 100%|██████████| 35/35 [00:10<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5907, Train Acc: 78.80%\n",
      "Val Loss: 0.5988, Val Acc: 80.43%\n",
      "\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:29<00:00,  1.55it/s, loss=0.0687, acc=81.5]\n",
      "Validation: 100%|██████████| 35/35 [00:07<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5495, Train Acc: 81.52%\n",
      "Val Loss: 0.6008, Val Acc: 76.45%\n",
      "\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:35<00:00,  1.44it/s, loss=0.0773, acc=79.8]\n",
      "Validation: 100%|██████████| 35/35 [00:12<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6180, Train Acc: 79.80%\n",
      "Val Loss: 0.4899, Val Acc: 84.06%\n",
      "Saved best model with accuracy: 84.06%\n",
      "\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:41<00:00,  1.35it/s, loss=0.0664, acc=82.6]\n",
      "Validation: 100%|██████████| 35/35 [00:12<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5311, Train Acc: 82.61%\n",
      "Val Loss: 0.7411, Val Acc: 75.36%\n",
      "\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:41<00:00,  1.36it/s, loss=0.077, acc=79.7] \n",
      "Validation: 100%|██████████| 35/35 [00:12<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6163, Train Acc: 79.71%\n",
      "Val Loss: 0.4742, Val Acc: 84.78%\n",
      "Saved best model with accuracy: 84.78%\n",
      "\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:39<00:00,  1.38it/s, loss=0.0477, acc=87.5]\n",
      "Validation: 100%|██████████| 35/35 [00:09<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3816, Train Acc: 87.50%\n",
      "Val Loss: 0.4582, Val Acc: 87.32%\n",
      "Saved best model with accuracy: 87.32%\n",
      "\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:28<00:00,  1.56it/s, loss=0.0437, acc=89.3]\n",
      "Validation: 100%|██████████| 35/35 [00:10<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3492, Train Acc: 89.31%\n",
      "Val Loss: 0.4158, Val Acc: 88.04%\n",
      "Saved best model with accuracy: 88.04%\n",
      "\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:38<00:00,  1.40it/s, loss=0.0503, acc=87.7]\n",
      "Validation: 100%|██████████| 35/35 [00:13<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4023, Train Acc: 87.68%\n",
      "Val Loss: 0.5134, Val Acc: 85.14%\n",
      "\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:41<00:00,  1.36it/s, loss=0.0341, acc=91.6]\n",
      "Validation: 100%|██████████| 35/35 [00:13<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2731, Train Acc: 91.58%\n",
      "Val Loss: 0.2683, Val Acc: 92.39%\n",
      "Saved best model with accuracy: 92.39%\n",
      "\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:36<00:00,  1.42it/s, loss=0.0497, acc=87.4]\n",
      "Validation: 100%|██████████| 35/35 [00:09<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3978, Train Acc: 87.41%\n",
      "Val Loss: 0.4987, Val Acc: 83.33%\n",
      "\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:40<00:00,  1.37it/s, loss=0.0488, acc=87.5]\n",
      "Validation: 100%|██████████| 35/35 [00:10<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3905, Train Acc: 87.50%\n",
      "Val Loss: 0.7522, Val Acc: 77.17%\n",
      "\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:41<00:00,  1.36it/s, loss=0.0445, acc=89.4]\n",
      "Validation: 100%|██████████| 35/35 [00:08<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3557, Train Acc: 89.40%\n",
      "Val Loss: 0.4449, Val Acc: 88.77%\n",
      "\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:34<00:00,  1.46it/s, loss=0.0318, acc=91.4]\n",
      "Validation: 100%|██████████| 35/35 [00:10<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2542, Train Acc: 91.39%\n",
      "Val Loss: 0.3037, Val Acc: 90.94%\n",
      "\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:43<00:00,  1.33it/s, loss=0.0288, acc=92.9]\n",
      "Validation: 100%|██████████| 35/35 [00:12<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2305, Train Acc: 92.93%\n",
      "Val Loss: 0.4865, Val Acc: 85.51%\n",
      "\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:49<00:00,  1.26it/s, loss=0.032, acc=91.5] \n",
      "Validation: 100%|██████████| 35/35 [00:09<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2558, Train Acc: 91.49%\n",
      "Val Loss: 0.2750, Val Acc: 93.12%\n",
      "Saved best model with accuracy: 93.12%\n",
      "\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:46<00:00,  1.29it/s, loss=0.0211, acc=94.5]\n",
      "Validation: 100%|██████████| 35/35 [00:12<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1690, Train Acc: 94.47%\n",
      "Val Loss: 0.3383, Val Acc: 90.94%\n",
      "\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:43<00:00,  1.33it/s, loss=0.0324, acc=92.8]\n",
      "Validation: 100%|██████████| 35/35 [00:10<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2593, Train Acc: 92.75%\n",
      "Val Loss: 0.3866, Val Acc: 90.94%\n",
      "\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:43<00:00,  1.33it/s, loss=0.0214, acc=95]  \n",
      "Validation: 100%|██████████| 35/35 [00:07<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1712, Train Acc: 95.02%\n",
      "Val Loss: 0.4240, Val Acc: 88.77%\n",
      "\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:34<00:00,  1.46it/s, loss=0.0283, acc=93.2]\n",
      "Validation: 100%|██████████| 35/35 [00:07<00:00,  4.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2265, Train Acc: 93.21%\n",
      "Val Loss: 0.2688, Val Acc: 92.39%\n",
      "\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:34<00:00,  1.46it/s, loss=0.0138, acc=97.5]\n",
      "Validation: 100%|██████████| 35/35 [00:08<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1104, Train Acc: 97.46%\n",
      "Val Loss: 0.3290, Val Acc: 92.03%\n",
      "\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:38<00:00,  1.41it/s, loss=0.0254, acc=94.2]\n",
      "Validation: 100%|██████████| 35/35 [00:10<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2028, Train Acc: 94.20%\n",
      "Val Loss: 0.3296, Val Acc: 91.30%\n",
      "\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:53<00:00,  1.22it/s, loss=0.0162, acc=96.2]\n",
      "Validation: 100%|██████████| 35/35 [00:12<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1294, Train Acc: 96.20%\n",
      "Val Loss: 0.3205, Val Acc: 90.94%\n",
      "\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:57<00:00,  1.17it/s, loss=0.0109, acc=97.5] \n",
      "Validation: 100%|██████████| 35/35 [00:13<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0871, Train Acc: 97.46%\n",
      "Val Loss: 0.2925, Val Acc: 94.20%\n",
      "Saved best model with accuracy: 94.20%\n",
      "\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:47<00:00,  1.28it/s, loss=0.0084, acc=98.2] \n",
      "Validation: 100%|██████████| 35/35 [00:09<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0672, Train Acc: 98.19%\n",
      "Val Loss: 0.2550, Val Acc: 93.12%\n",
      "\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:51<00:00,  1.24it/s, loss=0.00837, acc=98]  \n",
      "Validation: 100%|██████████| 35/35 [00:12<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0669, Train Acc: 98.01%\n",
      "Val Loss: 0.3759, Val Acc: 90.94%\n",
      "\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:58<00:00,  1.17it/s, loss=0.00928, acc=97.5]\n",
      "Validation: 100%|██████████| 35/35 [00:12<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0742, Train Acc: 97.46%\n",
      "Val Loss: 0.3271, Val Acc: 91.67%\n",
      "\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [02:04<00:00,  1.11it/s, loss=0.0079, acc=98.2] \n",
      "Validation: 100%|██████████| 35/35 [00:16<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0632, Train Acc: 98.19%\n",
      "Val Loss: 0.2601, Val Acc: 93.84%\n",
      "\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:52<00:00,  1.23it/s, loss=0.00362, acc=99.5]\n",
      "Validation: 100%|██████████| 35/35 [00:10<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0290, Train Acc: 99.46%\n",
      "Val Loss: 0.3341, Val Acc: 92.03%\n",
      "\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:37<00:00,  1.42it/s, loss=0.00551, acc=98.7]\n",
      "Validation: 100%|██████████| 35/35 [00:10<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0441, Train Acc: 98.73%\n",
      "Val Loss: 0.3229, Val Acc: 94.20%\n",
      "\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:42<00:00,  1.35it/s, loss=0.00351, acc=99.3]\n",
      "Validation: 100%|██████████| 35/35 [00:08<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0281, Train Acc: 99.28%\n",
      "Val Loss: 0.2968, Val Acc: 93.84%\n",
      "\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:33<00:00,  1.48it/s, loss=0.00196, acc=99.6]\n",
      "Validation: 100%|██████████| 35/35 [00:08<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0157, Train Acc: 99.64%\n",
      "Val Loss: 0.2823, Val Acc: 95.29%\n",
      "Saved best model with accuracy: 95.29%\n",
      "\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:39<00:00,  1.39it/s, loss=0.00496, acc=98.7]\n",
      "Validation: 100%|██████████| 35/35 [00:07<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0396, Train Acc: 98.73%\n",
      "Val Loss: 0.3519, Val Acc: 93.12%\n",
      "\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 138/138 [01:38<00:00,  1.41it/s, loss=0.00438, acc=99]  \n",
      "Validation: 100%|██████████| 35/35 [00:09<00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0350, Train Acc: 99.00%\n",
      "Val Loss: 0.3355, Val Acc: 93.12%\n",
      "\n",
      "Training completed! Best validation accuracy: 95.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "UCF50 Video Classification using Recurrent Neural Networks\n",
    "Implements multiple architectures: Single Frame, Early Fusion, Late Fusion, CNN+LSTM, ConvLSTM\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# SET RANDOM SEEDS\n",
    "# ============================================================================\n",
    "mySeed = 42\n",
    "np.random.seed(mySeed)\n",
    "random.seed(mySeed)\n",
    "torch.manual_seed(mySeed)\n",
    "torch.cuda.manual_seed(mySeed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "class Config:\n",
    "    # Data parameters\n",
    "    DATA_PATH = 'UCF50'  # Update this path\n",
    "    NUM_FRAMES = 20  # Use first 20 frames\n",
    "    IMG_SIZE = (112, 112)  # Frame size\n",
    "    \n",
    "    # Class range - Change this for each of the 5 runs\n",
    "    # Run 1: (0, 10), Run 2: (10, 20), Run 3: (20, 30), Run 4: (30, 40), Run 5: (40, 50)\n",
    "    CLASS_START = 0\n",
    "    CLASS_END = 10\n",
    "    \n",
    "    # Training parameters\n",
    "    BATCH_SIZE = 8\n",
    "    EPOCHS = 50\n",
    "    LEARNING_RATE = 0.001\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Model selection: 'single_frame', 'early_fusion', 'late_fusion', 'cnn_lstm', 'conv_lstm'\n",
    "    MODEL_TYPE = 'cnn_lstm'\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# ============================================================================\n",
    "# DATASET CLASS\n",
    "# ============================================================================\n",
    "class UCF50Dataset(Dataset):\n",
    "    def __init__(self, video_paths, labels, transform=None, num_frames=20):\n",
    "        self.video_paths = video_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.num_frames = num_frames\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.video_paths)\n",
    "    \n",
    "    def load_video(self, path):\n",
    "        \"\"\"Load first num_frames from video\"\"\"\n",
    "        cap = cv2.VideoCapture(path)\n",
    "        frames = []\n",
    "        \n",
    "        for i in range(self.num_frames):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                # If video has fewer frames, repeat last frame\n",
    "                if len(frames) > 0:\n",
    "                    frames.append(frames[-1].copy())\n",
    "                else:\n",
    "                    # Create blank frame\n",
    "                    frames.append(np.zeros((config.IMG_SIZE[0], config.IMG_SIZE[1], 3), dtype=np.uint8))\n",
    "            else:\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame = cv2.resize(frame, config.IMG_SIZE)\n",
    "                frames.append(frame)\n",
    "        \n",
    "        cap.release()\n",
    "        return np.array(frames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        video_path = self.video_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Load video frames\n",
    "        frames = self.load_video(video_path)\n",
    "        \n",
    "        # Apply transforms to each frame\n",
    "        if self.transform:\n",
    "            frames = np.stack([self.transform(frame) for frame in frames])\n",
    "        else:\n",
    "            frames = torch.FloatTensor(frames).permute(0, 3, 1, 2) / 255.0\n",
    "        \n",
    "        return frames, label\n",
    "\n",
    "# ============================================================================\n",
    "# DATA LOADING FUNCTIONS\n",
    "# ============================================================================\n",
    "def load_ucf50_data(data_path, class_start=0, class_end=10):\n",
    "    \"\"\"Load video paths and labels for specified class range\"\"\"\n",
    "    data_path = Path(data_path)\n",
    "    video_paths = []\n",
    "    labels = []\n",
    "    class_names = sorted([d.name for d in data_path.iterdir() if d.is_dir()])\n",
    "    \n",
    "    # Select classes in range\n",
    "    selected_classes = class_names[class_start:class_end]\n",
    "    class_to_idx = {cls: idx for idx, cls in enumerate(selected_classes)}\n",
    "    \n",
    "    print(f\"Loading classes {class_start} to {class_end-1}: {selected_classes}\")\n",
    "    \n",
    "    for class_name in selected_classes:\n",
    "        class_path = data_path / class_name\n",
    "        for video_file in class_path.glob('*.avi'):\n",
    "            video_paths.append(str(video_file))\n",
    "            labels.append(class_to_idx[class_name])\n",
    "    \n",
    "    return video_paths, labels, len(selected_classes)\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL ARCHITECTURES\n",
    "# ============================================================================\n",
    "\n",
    "class SingleFrameCNN(nn.Module):\n",
    "    \"\"\"Single Frame Classification - Most common frame class wins\"\"\"\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "        self.features = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, num_frames, channels, height, width)\n",
    "        batch_size, num_frames = x.shape[0], x.shape[1]\n",
    "        \n",
    "        # Process each frame independently\n",
    "        x = x.view(batch_size * num_frames, *x.shape[2:])\n",
    "        features = self.features(x)\n",
    "        features = features.view(batch_size, num_frames, -1)\n",
    "        \n",
    "        # Classify each frame\n",
    "        logits = self.fc(features)  # (batch, num_frames, num_classes)\n",
    "        \n",
    "        # Average predictions across frames\n",
    "        output = logits.mean(dim=1)\n",
    "        return output\n",
    "\n",
    "class EarlyFusionCNN(nn.Module):\n",
    "    \"\"\"Early Fusion - Concatenate frames in channel dimension\"\"\"\n",
    "    def __init__(self, num_classes, num_frames=20):\n",
    "        super().__init__()\n",
    "        self.num_frames = num_frames\n",
    "        \n",
    "        # Modified first conv to accept num_frames * 3 channels\n",
    "        self.conv1 = nn.Conv2d(num_frames * 3, 64, kernel_size=7, stride=2, padding=3)\n",
    "        \n",
    "        # Rest of ResNet\n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "        self.layer1 = resnet.layer1\n",
    "        self.layer2 = resnet.layer2\n",
    "        self.layer3 = resnet.layer3\n",
    "        self.layer4 = resnet.layer4\n",
    "        self.avgpool = resnet.avgpool\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, num_frames, channels, height, width)\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # Concatenate all frames in channel dimension\n",
    "        x = x.view(batch_size, -1, *x.shape[3:])  # (batch, num_frames*3, H, W)\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class LateFusionCNN(nn.Module):\n",
    "    \"\"\"Late Fusion - Concatenate CNN features before final classification\"\"\"\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "        self.features = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, num_frames, channels, height, width)\n",
    "        batch_size, num_frames = x.shape[0], x.shape[1]\n",
    "        \n",
    "        # Process each frame independently\n",
    "        x = x.view(batch_size * num_frames, *x.shape[2:])\n",
    "        features = self.features(x)\n",
    "        features = features.view(batch_size, num_frames, -1)\n",
    "        \n",
    "        # Average features across frames (late fusion)\n",
    "        fused_features = features.mean(dim=1)\n",
    "        output = self.fc(fused_features)\n",
    "        return output\n",
    "\n",
    "class CNNLSTM(nn.Module):\n",
    "    \"\"\"CNN + LSTM - Extract CNN features then process with LSTM\"\"\"\n",
    "    def __init__(self, num_classes, hidden_size=256, num_layers=2):\n",
    "        super().__init__()\n",
    "        # CNN feature extractor\n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "        self.cnn = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        \n",
    "        # LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=512,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=0.5\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, num_frames, channels, height, width)\n",
    "        batch_size, num_frames = x.shape[0], x.shape[1]\n",
    "        \n",
    "        # Extract CNN features for each frame\n",
    "        x = x.view(batch_size * num_frames, *x.shape[2:])\n",
    "        cnn_features = self.cnn(x)\n",
    "        cnn_features = cnn_features.view(batch_size, num_frames, -1)\n",
    "        \n",
    "        # Process sequence with LSTM\n",
    "        lstm_out, (h_n, c_n) = self.lstm(cnn_features)\n",
    "        \n",
    "        # Use last hidden state\n",
    "        output = self.fc(h_n[-1])\n",
    "        return output\n",
    "\n",
    "class ConvLSTMCell(nn.Module):\n",
    "    \"\"\"Convolutional LSTM Cell\"\"\"\n",
    "    def __init__(self, input_channels, hidden_channels, kernel_size):\n",
    "        super().__init__()\n",
    "        self.input_channels = input_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = kernel_size // 2\n",
    "        \n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=input_channels + hidden_channels,\n",
    "            out_channels=4 * hidden_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=self.padding\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        h_prev, c_prev = hidden\n",
    "        \n",
    "        combined = torch.cat([x, h_prev], dim=1)\n",
    "        gates = self.conv(combined)\n",
    "        \n",
    "        # Split gates\n",
    "        i, f, o, g = torch.split(gates, self.hidden_channels, dim=1)\n",
    "        \n",
    "        i = torch.sigmoid(i)\n",
    "        f = torch.sigmoid(f)\n",
    "        o = torch.sigmoid(o)\n",
    "        g = torch.tanh(g)\n",
    "        \n",
    "        c_cur = f * c_prev + i * g\n",
    "        h_cur = o * torch.tanh(c_cur)\n",
    "        \n",
    "        return h_cur, c_cur\n",
    "\n",
    "class ConvLSTM(nn.Module):\n",
    "    \"\"\"ConvLSTM - LSTM with convolutional operations\"\"\"\n",
    "    def __init__(self, num_classes, hidden_channels=64):\n",
    "        super().__init__()\n",
    "        self.hidden_channels = hidden_channels\n",
    "        \n",
    "        # Initial conv to reduce dimensions\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=7, stride=2, padding=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        # ConvLSTM layers\n",
    "        self.convlstm1 = ConvLSTMCell(32, hidden_channels, kernel_size=3)\n",
    "        self.convlstm2 = ConvLSTMCell(hidden_channels, hidden_channels, kernel_size=3)\n",
    "        \n",
    "        # Final classification\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(hidden_channels, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, num_frames, channels, height, width)\n",
    "        batch_size, num_frames = x.shape[0], x.shape[1]\n",
    "        \n",
    "        # Process first frame to get spatial dimensions\n",
    "        x0 = self.conv1(x[:, 0])\n",
    "        h, w = x0.shape[2], x0.shape[3]\n",
    "        \n",
    "        # Initialize hidden states\n",
    "        h1 = torch.zeros(batch_size, self.hidden_channels, h, w).to(x.device)\n",
    "        c1 = torch.zeros(batch_size, self.hidden_channels, h, w).to(x.device)\n",
    "        h2 = torch.zeros(batch_size, self.hidden_channels, h, w).to(x.device)\n",
    "        c2 = torch.zeros(batch_size, self.hidden_channels, h, w).to(x.device)\n",
    "        \n",
    "        # Process each frame through ConvLSTM\n",
    "        for t in range(num_frames):\n",
    "            x_t = self.conv1(x[:, t])\n",
    "            h1, c1 = self.convlstm1(x_t, (h1, c1))\n",
    "            h2, c2 = self.convlstm2(h1, (h2, c2))\n",
    "        \n",
    "        # Use final hidden state\n",
    "        output = self.avgpool(h2)\n",
    "        output = output.view(batch_size, -1)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "\n",
    "# ============================================================================\n",
    "# TRAINING FUNCTIONS\n",
    "# ============================================================================\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc='Training')\n",
    "    for frames, labels in pbar:\n",
    "        frames = frames.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(frames)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        pbar.set_postfix({'loss': running_loss/total, 'acc': 100.*correct/total})\n",
    "    \n",
    "    return running_loss / len(dataloader), 100. * correct / total\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for frames, labels in tqdm(dataloader, desc='Validation'):\n",
    "            frames = frames.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(frames)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return running_loss / len(dataloader), 100. * correct / total\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN TRAINING LOOP\n",
    "# ============================================================================\n",
    "def main():\n",
    "    print(f\"Using device: {config.DEVICE}\")\n",
    "    print(f\"Processing classes {config.CLASS_START} to {config.CLASS_END-1}\")\n",
    "    print(f\"Model type: {config.MODEL_TYPE}\")\n",
    "    \n",
    "    # Load data\n",
    "    video_paths, labels, num_classes = load_ucf50_data(\n",
    "        config.DATA_PATH, \n",
    "        config.CLASS_START, \n",
    "        config.CLASS_END\n",
    "    )\n",
    "    \n",
    "    # Train-test split\n",
    "    train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "        video_paths, labels, test_size=0.2, random_state=mySeed, stratify=labels\n",
    "    )\n",
    "    \n",
    "    print(f\"Training samples: {len(train_paths)}, Validation samples: {len(val_paths)}\")\n",
    "    \n",
    "    # Data augmentation\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = UCF50Dataset(train_paths, train_labels, train_transform, config.NUM_FRAMES)\n",
    "    val_dataset = UCF50Dataset(val_paths, val_labels, val_transform, config.NUM_FRAMES)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config.BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "    \n",
    "    # Create model\n",
    "    if config.MODEL_TYPE == 'single_frame':\n",
    "        model = SingleFrameCNN(num_classes)\n",
    "    elif config.MODEL_TYPE == 'early_fusion':\n",
    "        model = EarlyFusionCNN(num_classes, config.NUM_FRAMES)\n",
    "    elif config.MODEL_TYPE == 'late_fusion':\n",
    "        model = LateFusionCNN(num_classes)\n",
    "    elif config.MODEL_TYPE == 'cnn_lstm':\n",
    "        model = CNNLSTM(num_classes)\n",
    "    elif config.MODEL_TYPE == 'conv_lstm':\n",
    "        model = ConvLSTM(num_classes)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type: {config.MODEL_TYPE}\")\n",
    "    \n",
    "    model = model.to(config.DEVICE)\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.LEARNING_RATE)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5)\n",
    "    \n",
    "    # Training loop\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(config.EPOCHS):\n",
    "        print(f'\\nEpoch {epoch+1}/{config.EPOCHS}')\n",
    "        \n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, config.DEVICE)\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion, config.DEVICE)\n",
    "        \n",
    "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "        \n",
    "        scheduler.step(val_acc)\n",
    "        \n",
    "        # Save best model\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_acc': val_acc,\n",
    "            }, f'best_model_{config.MODEL_TYPE}_classes_{config.CLASS_START}_{config.CLASS_END}.pth')\n",
    "            print(f'Saved best model with accuracy: {best_acc:.2f}%')\n",
    "    \n",
    "    print(f'\\nTraining completed! Best validation accuracy: {best_acc:.2f}%')\n",
    "    return best_acc\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
